# ğŸ‰ Status do Projeto - Data Engineering Pipeline

## âœ… TODOS OS SERVIÃ‡OS FUNCIONANDO!

Data: 03/10/2025  
Status: **OPERACIONAL** âœ…

---

## ğŸ“Š ServiÃ§os DisponÃ­veis

### 1. **Dashboard Streamlit** 
- **URL:** http://localhost:8501
- **Funcionalidades:**
  - ğŸ“ˆ VisÃ£o geral do pipeline com mÃ©tricas em tempo real
  - ğŸ¯ Controle de DAGs do Airflow
  - ğŸ“Š VisualizaÃ§Ã£o das 4 camadas de dados (Raw, Staging, Processed, Analytics)
  - ğŸ² Gerador de dados com Faker
- **Status:** âœ… Funcionando (HTTP 200)

### 2. **Apache Airflow**
- **URL:** http://localhost:8080
- **Credenciais:** 
  - User: `admin`
  - Password: `admin`
- **Funcionalidades:**
  - OrquestraÃ§Ã£o de workflows
  - 4 DAGs disponÃ­veis:
    - `ecommerce_etl_pipeline` - Pipeline ETL principal
    - `api_ingestion_dag` - IngestÃ£o de APIs
    - `data_quality_dag` - VerificaÃ§Ã£o de qualidade
    - `minio_datalake_dag` - IntegraÃ§Ã£o com MinIO
- **Status:** âœ… Funcionando (HTTP 302 redirect, Metadatabase: healthy, Scheduler: healthy)

### 3. **Apache Spark**
- **Master UI:** http://localhost:8081
- **Master URL:** spark://spark-master:7077
- **ConfiguraÃ§Ã£o:**
  - 1 Master node
  - 1 Worker node
  - Worker Memory: 96MB
  - Worker Cores: 1
- **Status:** âœ… Funcionando (HTTP 200)

### 4. **MinIO (Object Storage)**
- **Console:** http://localhost:9001
- **API:** http://localhost:9000
- **Credenciais:**
  - Access Key: `minioadmin`
  - Secret Key: `minioadmin`
- **Funcionalidades:**
  - S3-compatible object storage
  - Datalake storage
- **Status:** âœ… Funcionando (HTTP 200, Healthy)

### 5. **PostgreSQL**
- **Host:** localhost
- **Port:** 5432
- **Databases:**
  - `datawarehouse` - Data Warehouse principal
  - `airflow` - Metadados do Airflow
  - `metabase` - Metadados do Metabase (opcional)
- **Credenciais:**
  - User: `postgres`
  - Password: `postgres`
- **Schemas:**
  - `raw` - Dados brutos
  - `staging` - Dados em staging
  - `processed` - Dados processados
  - `analytics` - Dados analÃ­ticos
- **Status:** âœ… Funcionando

---

## ğŸ’¾ Uso de MemÃ³ria

| Container | Uso Atual | Limite | Percentual |
|-----------|-----------|--------|------------|
| Airflow Webserver | ~390 MB | 512 MB | 76% |
| Airflow Scheduler | ~174 MB | 300 MB | 58% |
| Spark Master | ~123 MB | 128 MB | 96% |
| Dashboard | ~87 MB | 128 MB | 68% |
| MinIO | ~92 MB | 96 MB | 96% |
| PostgreSQL | ~22 MB | 128 MB | 17% |
| Spark Worker | ~1 MB | 128 MB | 1% |
| **TOTAL** | **~890 MB** | **1420 MB** | **63%** |

> âš ï¸ **Nota:** Para funcionar corretamente, o projeto usa aproximadamente **890 MB de RAM**. 
> Embora seja possÃ­vel reduzir para 900 MB, isso pode causar instabilidade no Airflow.

---

## ğŸ—ï¸ Arquitetura de Dados (4 Camadas)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LAYER 4: ANALYTICS                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ â€¢ sales_summary (agregaÃ§Ãµes de vendas)               â”‚  â”‚
â”‚  â”‚ â€¢ MÃ©tricas de negÃ³cio                                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–²
                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   LAYER 3: PROCESSED                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ â€¢ dim_customer (dimensÃ£o clientes)                   â”‚  â”‚
â”‚  â”‚ â€¢ dim_product (dimensÃ£o produtos)                    â”‚  â”‚
â”‚  â”‚ â€¢ dim_date (dimensÃ£o tempo)                          â”‚  â”‚
â”‚  â”‚ â€¢ fact_sales (fato vendas)                           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–²
                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LAYER 2: STAGING                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ â€¢ customers_staging (validado)                       â”‚  â”‚
â”‚  â”‚ â€¢ products_staging (validado)                        â”‚  â”‚
â”‚  â”‚ â€¢ transactions_staging (validado)                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–²
                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     LAYER 1: RAW                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ â€¢ customers_raw (dados brutos)                       â”‚  â”‚
â”‚  â”‚ â€¢ products_raw (dados brutos)                        â”‚  â”‚
â”‚  â”‚ â€¢ transactions_raw (dados brutos)                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Como Usar

### 1. Iniciar o Projeto
```bash
cd /home/synev1/dev/vmpro1
docker-compose up -d
```

### 2. Verificar Status
```bash
docker-compose ps
```

### 3. Acessar Dashboard
Abra o navegador em: http://localhost:8501

### 4. Gerar Dados de Teste
1. Acesse o Dashboard (http://localhost:8501)
2. VÃ¡ na aba "ğŸ² Gerador Faker"
3. Configure os parÃ¢metros desejados
4. Clique em "ğŸš€ Gerar Dados"

### 5. Executar DAG no Airflow
1. Acesse http://localhost:8080
2. Login: `admin` / `admin`
3. Ative a DAG desejada
4. Clique em "Trigger DAG"

### 6. Monitorar ExecuÃ§Ã£o
- **Dashboard:** Aba "ğŸ“Š DAGs em Andamento"
- **Airflow UI:** http://localhost:8080
- **Spark UI:** http://localhost:8081

### 7. Parar o Projeto
```bash
docker-compose down
```

---

## ğŸ”§ ResoluÃ§Ã£o de Problemas

### Porta 5432 jÃ¡ em uso
```bash
docker stop verihfy-postgres
docker-compose up -d
```

### Airflow nÃ£o inicia
```bash
# Verificar logs
docker logs de_airflow_webserver --tail 50
docker logs de_airflow_scheduler --tail 50

# Reiniciar
docker restart de_airflow_webserver de_airflow_scheduler
```

### Dashboard com erro
```bash
# Verificar logs
docker logs de_data_dashboard --tail 50

# Reiniciar
docker restart de_data_dashboard
```

### Limpar e reiniciar tudo
```bash
docker-compose down -v  # Remove volumes tambÃ©m
docker-compose up -d
```

---

## ğŸ“ DAGs DisponÃ­veis

### 1. `ecommerce_etl_pipeline`
- **DescriÃ§Ã£o:** Pipeline ETL completo para e-commerce
- **Schedule:** DiÃ¡rio
- **Tarefas:**
  1. Gerar dados de exemplo
  2. Carregar na camada RAW
  3. Transformar e limpar
  4. Carregar dimensÃµes (customer, product, date)
  5. Carregar fato (sales)
  6. Criar agregaÃ§Ãµes analÃ­ticas

### 2. `api_ingestion_dag`
- **DescriÃ§Ã£o:** IngestÃ£o de dados de APIs externas
- **Schedule:** A cada 6 horas

### 3. `data_quality_dag`
- **DescriÃ§Ã£o:** VerificaÃ§Ã£o de qualidade dos dados
- **Schedule:** DiÃ¡rio

### 4. `minio_datalake_dag`
- **DescriÃ§Ã£o:** IntegraÃ§Ã£o com MinIO para datalake
- **Schedule:** Manual

---

## ğŸ“¦ Pacotes Python Instalados

- `faker` - GeraÃ§Ã£o de dados fake
- `minio` - Cliente MinIO/S3
- `psycopg2-binary` - Driver PostgreSQL
- `streamlit` - Framework web dashboard
- `pandas` - ManipulaÃ§Ã£o de dados
- `plotly` - VisualizaÃ§Ãµes interativas
- `requests` - Cliente HTTP

---

## âœ¨ Funcionalidades do Dashboard

### Aba 1: VisÃ£o Geral
- Total de registros por camada
- Receita total
- GrÃ¡fico de vendas por categoria
- GrÃ¡fico de mÃ©todos de pagamento

### Aba 2: DAGs em Andamento
- Status de todas as DAGs
- Ãšltima execuÃ§Ã£o
- PrÃ³xima execuÃ§Ã£o agendada
- BotÃµes para trigger manual

### Aba 3: Camadas de Dados
- VisualizaÃ§Ã£o de dados de cada camada
- Filtros e busca
- Export para CSV

### Aba 4: Gerador Faker
- ConfiguraÃ§Ã£o de quantidade de registros
- SeleÃ§Ã£o de categorias e mÃ©todos de pagamento
- PerÃ­odo de datas
- GeraÃ§Ã£o automÃ¡tica com progresso

---

## ğŸ¯ PrÃ³ximos Passos

1. âœ… **Projeto funcionando** - Todos os serviÃ§os operacionais
2. âœ… **Dashboard integrado** - Interface web completa
3. âœ… **Gerador Faker** - CriaÃ§Ã£o de dados de teste
4. ğŸ”„ **OtimizaÃ§Ã£o de memÃ³ria** - Reduzir para 900MB (opcional)
5. ğŸ“Š **Adicionar Metabase** - BI Tool para visualizaÃ§Ãµes
6. ğŸ” **SeguranÃ§a** - Adicionar autenticaÃ§Ã£o robusta
7. ğŸ“ˆ **Monitoramento** - Prometheus + Grafana

---

**Desenvolvido com â¤ï¸ usando Docker, Airflow, Spark, PostgreSQL, MinIO e Streamlit**
