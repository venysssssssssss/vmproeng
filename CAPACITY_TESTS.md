# üìä Testes de Capacidade - Data Engineering Pipeline

## Objetivo
Descobrir a capacidade m√°xima de ingest√£o de dados com 900MB de RAM

---

## üîß Como Usar

### 1. Monitorar Mem√≥ria em Tempo Real
```bash
chmod +x monitor_memory.sh
./monitor_memory.sh
```

### 2. Executar Teste de Capacidade
```bash
# Sintaxe: python test_capacity.py <batch_size> <num_batches> <delay>
/home/synev1/dev/vmpro1/.venv/bin/python test_capacity.py 1000 50 1

# Exemplos:
# Teste pequeno: 5,000 registros
/home/synev1/dev/vmpro1/.venv/bin/python test_capacity.py 500 10 1

# Teste m√©dio: 50,000 registros
/home/synev1/dev/vmpro1/.venv/bin/python test_capacity.py 1000 50 1

# Teste grande: 100,000 registros
/home/synev1/dev/vmpro1/.venv/bin/python test_capacity.py 2000 50 1
```

### 3. Ver Uso de Mem√≥ria Atual
```bash
docker stats --no-stream $(docker-compose ps -q) --format "table {{.Name}}\t{{.MemUsage}}"
```

---

## üìà Resultados dos Testes

### Teste 1: 10,000 registros (Baseline)
**Data:** 03/10/2025  
**Configura√ß√£o:**
- Batch Size: 1,000 registros
- N√∫mero de Batches: 10
- Delay: 2s
- Total: 10,000 registros

**Resultados:**
- ‚úÖ **Tempo Total:** 25.7s (0.4 minutos)
- ‚úÖ **Taxa:** 389 registros/segundo
- ‚úÖ **Tempo m√©dio/batch:** 0.77s
- ‚úÖ **Batch mais r√°pido:** 0.69s
- ‚úÖ **Batch mais lento:** 0.85s

**Dados Inseridos:**
- Raw Transactions: 10,000
- Raw Customers: 6,054
- Raw Products: 900

**Uso de Mem√≥ria (ap√≥s teste):**
| Container | Mem√≥ria Usada | Limite | Percentual |
|-----------|---------------|---------|------------|
| Airflow Scheduler | 185.6 MB | 300 MB | 61.9% |
| Airflow Webserver | ~390 MB | 512 MB | ~76% |
| Dashboard | 125.3 MB | 128 MB | 97.9% |
| PostgreSQL | **27.0 MB** | 128 MB | 21.1% |
| Spark Master | 125.1 MB | 128 MB | 97.7% |
| Spark Worker | 0.8 MB | 128 MB | 0.6% |
| MinIO | 92.2 MB | 96 MB | 96.0% |
| **TOTAL** | **~946 MB** | 1,420 MB | **66.6%** |

**An√°lise:**
- PostgreSQL aumentou de 22MB para 27MB (+5MB para 10K registros)
- Proje√ß√£o: ~0.5MB por 1,000 registros
- Sistema est√°vel, sem picos de mem√≥ria

---

### Teste 2: 50,000 registros (Carga M√©dia)
**Status:** üîÑ Pendente

**Proje√ß√£o:**
- Tempo estimado: ~2 minutos
- Mem√≥ria PostgreSQL estimada: ~47 MB
- Total estimado: ~966 MB

---

### Teste 3: 100,000 registros (Carga Alta)
**Status:** üîÑ Pendente

**Proje√ß√£o:**
- Tempo estimado: ~4 minutos
- Mem√≥ria PostgreSQL estimada: ~72 MB
- Total estimado: ~991 MB

---

### Teste 4: 500,000 registros (Carga M√°xima)
**Status:** üîÑ Pendente

**Proje√ß√£o:**
- Tempo estimado: ~20 minutos
- Mem√≥ria PostgreSQL estimada: ~272 MB (pode exceder limite de 128MB)
- Total estimado: ~1,191 MB ‚ö†Ô∏è **ACIMA DO LIMITE**

---

## üí° Insights

### Capacidade Estimada
Com base no teste de 10K registros:

**Cen√°rio Conservador (900MB total):**
- Mem√≥ria dispon√≠vel para dados: ~50 MB
- Capacidade estimada: **~100,000 registros**
- Taxa de ingest√£o: ~390 registros/segundo

**Cen√°rio Otimizado (reduzindo outros servi√ßos):**
- Se reduzir Dashboard para 96MB: +29MB dispon√≠vel
- Se reduzir Spark Master para 96MB: +29MB dispon√≠vel
- Total adicional: ~58MB
- Capacidade otimizada: **~200,000 registros**

### Gargalos Identificados
1. **Dashboard (125MB)** - Quase no limite
2. **Spark Master (125MB)** - Quase no limite
3. **MinIO (92MB)** - Quase no limite
4. **Airflow Webserver (390MB)** - Maior consumidor

### Recomenda√ß√µes

**Para maximizar capacidade com 900MB:**
1. ‚úÖ Desabilitar Dashboard durante ingest√£o pesada (economiza 125MB)
2. ‚úÖ Reduzir Airflow Webserver para 400MB (economiza 112MB)
3. ‚úÖ Usar SequentialExecutor ao inv√©s de LocalExecutor (economiza ~100MB)
4. ‚úÖ Reduzir Spark Master/Worker para 96MB cada (economiza 64MB)

**Ganho potencial:** +400MB = **~1,300MB total dispon√≠vel**
**Capacidade estimada:** **~400,000 registros**

---

## üéØ Pr√≥ximos Passos

1. [ ] Executar teste de 50,000 registros
2. [ ] Executar teste de 100,000 registros
3. [ ] Testar configura√ß√£o otimizada (sem Dashboard)
4. [ ] Medir tempo de processamento Spark ap√≥s ingest√£o
5. [ ] Testar DAGs do Airflow com dados em massa
6. [ ] Benchmark de queries anal√≠ticas

---

## üìù Notas

- Os testes foram executados com sistema em repouso (sem outras cargas)
- PostgreSQL com configura√ß√£o padr√£o (shared_buffers=32MB)
- Airflow com LocalExecutor (mais mem√≥ria, melhor performance)
- Dados gerados aleatoriamente com Faker

---

## üîç Comandos √öteis

```bash
# Ver dados inseridos
PGPASSWORD=postgres psql -h localhost -U postgres -d datawarehouse -c "
SELECT 
    'Raw Transactions' as layer, COUNT(*) as count FROM raw.transactions_raw
    UNION ALL
SELECT 'Raw Customers', COUNT(*) FROM raw.customers_raw
    UNION ALL
SELECT 'Raw Products', COUNT(*) FROM raw.products_raw;
"

# Limpar dados de teste
PGPASSWORD=postgres psql -h localhost -U postgres -d datawarehouse -c "
TRUNCATE TABLE raw.transactions_raw CASCADE;
TRUNCATE TABLE raw.customers_raw CASCADE;
TRUNCATE TABLE raw.products_raw CASCADE;
"

# Ver tamanho do banco
PGPASSWORD=postgres psql -h localhost -U postgres -d datawarehouse -c "
SELECT 
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
FROM pg_tables
WHERE schemaname IN ('raw', 'staging', 'processed', 'analytics')
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
"
```

---

**√öltima atualiza√ß√£o:** 03/10/2025  
**Status:** ‚úÖ Testes iniciais conclu√≠dos, sistema operacional
