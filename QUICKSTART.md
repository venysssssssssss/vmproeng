# ğŸš€ Quick Start - Projeto de Engenharia de Dados

## ğŸ“ Ordem de ExecuÃ§Ã£o

### 1ï¸âƒ£ Primeiro Acesso (ConfiguraÃ§Ã£o Inicial)

```bash
# JÃ¡ temos Python 3.11.9 via pyenv âœ“
# JÃ¡ temos Poetry configurado âœ“

# Verificar ambiente
poetry env info
poetry shell  # Ativar ambiente virtual
```

### 2ï¸âƒ£ Iniciar ServiÃ§os Docker

```bash
# OpÃ§Ã£o A: Usar script automatizado (RECOMENDADO)
./start.sh

# OpÃ§Ã£o B: Docker Compose manual
docker-compose up -d
```

**Aguarde 60-90 segundos** para todos os serviÃ§os iniciarem.

### 3ï¸âƒ£ Verificar SaÃºde do Sistema

```bash
# Executar teste completo
./test-project.sh

# OU verificaÃ§Ã£o rÃ¡pida
./health-check.sh

# OU manual
docker-compose ps
docker stats --no-stream
```

### 4ï¸âƒ£ Acessar Interfaces Web

| ServiÃ§o | URL | Credenciais |
|---------|-----|-------------|
| **Airflow** | http://localhost:8080 | admin / admin |
| **Spark** | http://localhost:8081 | - |
| **MinIO** | http://localhost:9001 | minioadmin / minioadmin |
| **Metabase** | http://localhost:3000 | Configurar no 1Âº acesso |

### 5ï¸âƒ£ Executar Pipeline de Dados

#### Via Airflow UI (Recomendado):
1. Acesse http://localhost:8080
2. Login: `admin` / `admin`
3. Ative a DAG `ecommerce_etl_pipeline` (toggle Ã  esquerda)
4. Clique no botÃ£o â–¶ï¸ "Trigger DAG"
5. Acompanhe em "Graph View"

#### Via Linha de Comando:
```bash
# Pipeline completo de ETL
docker exec de_airflow_webserver airflow dags trigger ecommerce_etl_pipeline

# Pipeline de ingestÃ£o de API
docker exec de_airflow_webserver airflow dags trigger api_data_ingestion

# VerificaÃ§Ã£o de qualidade
docker exec de_airflow_webserver airflow dags trigger data_quality_check

# Ou use o Makefile
make trigger-etl
make trigger-ingestion
make trigger-quality
```

### 6ï¸âƒ£ Verificar Resultados

```bash
# Conectar ao PostgreSQL
docker exec -it de_postgres psql -U postgres -d datawarehouse

# Verificar dados carregados
SELECT COUNT(*) FROM raw.sales_transactions;
SELECT COUNT(*) FROM processed.fact_sales;
SELECT * FROM analytics.daily_sales_summary ORDER BY summary_date DESC LIMIT 5;

# Sair
\q
```

### 7ï¸âƒ£ Parar o Projeto

```bash
# Parar serviÃ§os (mantÃ©m dados)
./stop.sh

# Parar e limpar tudo
./stop.sh --clean
```

## ğŸ“Š Comandos Ãšteis

### Make Commands (Atalhos)
```bash
make help              # Ver todos os comandos
make start             # Iniciar serviÃ§os
make stop              # Parar serviÃ§os
make logs              # Ver logs de todos
make logs-airflow      # Ver logs do Airflow
make status            # Status dos containers
make stats             # Uso de recursos
make trigger-etl       # Executar pipeline ETL
make backup-db         # Backup do banco
```

### Docker Commands
```bash
# Ver logs em tempo real
docker-compose logs -f

# Logs de serviÃ§o especÃ­fico
docker-compose logs -f airflow-scheduler

# Status dos containers
docker-compose ps

# Uso de recursos
docker stats

# Reiniciar serviÃ§o
docker-compose restart airflow-webserver
```

### Airflow Commands
```bash
# Listar DAGs
docker exec de_airflow_webserver airflow dags list

# Ver status de uma DAG
docker exec de_airflow_webserver airflow dags list-runs -d ecommerce_etl_pipeline

# Executar task especÃ­fica (para debug)
docker exec de_airflow_webserver airflow tasks test ecommerce_etl_pipeline generate_sales_data 2024-01-01
```

### PostgreSQL Commands
```bash
# Conectar ao banco
docker exec -it de_postgres psql -U postgres -d datawarehouse

# Query rÃ¡pida
docker exec de_postgres psql -U postgres -d datawarehouse -c "SELECT COUNT(*) FROM raw.sales_transactions;"

# Backup manual
docker exec de_postgres pg_dump -U postgres datawarehouse > backup.sql
```

## ğŸ› Troubleshooting RÃ¡pido

### Container nÃ£o inicia
```bash
docker-compose logs [nome-do-container]
docker-compose restart [nome-do-container]
docker-compose up -d --force-recreate [nome-do-container]
```

### DAGs nÃ£o aparecem no Airflow
```bash
# Verificar erros de import
docker exec de_airflow_webserver airflow dags list-import-errors

# Verificar logs do scheduler
docker-compose logs airflow-scheduler | grep -i error

# Reiniciar scheduler
docker-compose restart airflow-scheduler
```

### Erro de memÃ³ria
```bash
# Ver uso atual
docker stats

# Parar serviÃ§os nÃ£o essenciais
docker-compose stop metabase
docker-compose stop spark-worker
```

### Banco nÃ£o conecta
```bash
# Testar conexÃ£o
docker exec de_postgres pg_isready -U postgres

# Ver logs
docker-compose logs postgres

# Reiniciar
docker-compose restart postgres
```

## âœ… Checklist de VerificaÃ§Ã£o

- [ ] Python 3.11.9 instalado (pyenv)
- [ ] Poetry configurado
- [ ] Ambiente virtual ativo (`poetry shell`)
- [ ] Docker rodando
- [ ] 8 containers ativos
- [ ] Airflow acessÃ­vel (localhost:8080)
- [ ] PostgreSQL aceitando conexÃµes
- [ ] DAGs carregadas no Airflow
- [ ] Pipeline executado com sucesso
- [ ] Dados nas tabelas

## ğŸ“š DocumentaÃ§Ã£o Completa

- **Guia Detalhado**: [RUN_PROJECT.md](RUN_PROJECT.md)
- **Arquitetura**: [ARCHITECTURE.md](ARCHITECTURE.md)
- **Uso**: [USAGE_GUIDE.md](USAGE_GUIDE.md)
- **Setup Python**: [SETUP_PYTHON.md](SETUP_PYTHON.md)
- **Roadmap**: [ROADMAP.md](ROADMAP.md)

## ğŸ¯ Fluxo de Dados

```
API/Files â†’ RAW â†’ STAGING â†’ PROCESSED (Star Schema) â†’ ANALYTICS â†’ BI
              â†“      â†“           â†“                        â†“
            MinIO  Clean    Dimensions/Facts        Aggregations
```

## ğŸ“ˆ PrÃ³ximos Passos

1. âœ… Rodar o projeto com `./start.sh`
2. âœ… Executar pipeline com `make trigger-etl`
3. âœ… Verificar dados no PostgreSQL
4. ğŸ“Š Configurar dashboards no Metabase
5. ğŸ”§ Personalizar DAGs para seus dados
6. ğŸš€ Adicionar novas fontes de dados

---

**Dica**: Sempre use `./test-project.sh` para validaÃ§Ã£o completa!
